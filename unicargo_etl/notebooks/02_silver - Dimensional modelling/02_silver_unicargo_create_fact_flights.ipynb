{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b553b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id, lpad, to_date, concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb66f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2A: READ BRONZE DATA ===\n",
    "print(\"Reading flights bronze data...\")\n",
    "\n",
    "flights_bronze_df = spark.read.table(\"unikargo_dev.01_bronze.unikargo_flights_bronze\")\n",
    "\n",
    "print(f\"Raw flights count: {flights_bronze_df.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2B: DATA CLEANSING (flights_clean) ===\n",
    "print(\"Cleansing flight data...\")\n",
    "\n",
    "flights_clean = (flights_bronze_df\n",
    "               # Filter out invalid flights   \n",
    "                .filter(col(\"flight_number\").isNotNull())\n",
    "                .filter(col(\"origin_airport\").isNotNull())\n",
    "                .filter(col(\"destination_airport\").isNotNull())\n",
    "                .filter(col(\"origin_airport\") != F.col(\"destination_airport\"))\n",
    "\n",
    "                # Create flight_date as DateType\n",
    "                .withColumn(\n",
    "                \"flight_date\",\n",
    "                to_date(\n",
    "                    concat(\n",
    "                    col(\"year\").cast(\"string\"),\n",
    "                    lit(\"-\"),\n",
    "                    lpad(col(\"month\").cast(\"string\"), 2, \"0\"),\n",
    "                    lit(\"-\"),\n",
    "                    lpad(col(\"day\").cast(\"string\"), 2, \"0\")\n",
    "                    ),\n",
    "                    \"yyyy-MM-dd\"\n",
    "                ).cast(\"date\")  # Explicit cast\n",
    "    )\n",
    "    # Remove rows with null flight_date\n",
    "    .filter(col(\"flight_date\").isNotNull())\n",
    "\n",
    "    # Drop duplicates based on flight and route\n",
    "    .dropDuplicates([\"flight_number\", \"flight_date\", \"origin_airport\", \"destination_airport\"]))\n",
    "\n",
    "clean_count = flights_clean.count()\n",
    "print(f\"Clean flights count: {clean_count:,}\")\n",
    "print(f\"Filtered out: {flights_bronze_df.count() - clean_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de658be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_clean.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb661f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2C: LOAD DIMENSION TABLES ===\n",
    "\n",
    "print(\"Reading silver dimension tables...\")\n",
    "\n",
    "dim_date_silver_df = spark.read.table(\"unikargo_dev.02_silver.unikargo_dim_date_silver\")\n",
    "dim_airline_silver_df = spark.read.table(\"unikargo_dev.02_silver.unikargo_dim_airline_silver\")\n",
    "dim_airport_silver_df = spark.read.table(\"unikargo_dev.02_silver.unikargo_dim_airport_silver\")\n",
    "\n",
    "print(f\"Dimensions loaded - Airlines: {dim_airline_silver_df.count()}, \"\n",
    "      f\"Airports: {dim_airport_silver_df.count()}, \"\n",
    "      f\"Dates: {dim_date_silver_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date_silver_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date_silver_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9243db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join flights with dim_date on YEAR, MONTH, DAY, DAY_OF_WEEK\n",
    "# flights_with_date_id = (\n",
    "#     dim_date_silver_df.alias(\"f\")\n",
    "#     .join(\n",
    "#         dim_date_silver_df.alias(\"d\"),\n",
    "#         on=[\"year\", \"month\", \"day\", \"day_of_week\"], \n",
    "#         how=\"left\"\n",
    "#     )\n",
    "#     # replace raw date columns with date_id\n",
    "#     .drop(\"year\", \"month\", \"day\", \"day_of_week\")\n",
    "#     .withColumnRenamed(\"date_id\", \"date_id\")\n",
    "# )\n",
    "\n",
    "# flights_with_date_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54aee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2D: CREATE FACT TABLE ===\n",
    "print(\"Creating fact table with surrogate key joins...\")\n",
    "\n",
    "# Start with flights_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb81f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact_flight = flights_clean.withColumn(\"flight_date_str\", col(\"flight_date\").cast(\"string\"))\n",
    "# dim_date_silver_df = dim_date_silver_df.withColumn(\"full_date_str\", col(\"full_date\").cast(\"string\"))\n",
    "\n",
    "# fact_flight_joined = fact_flight.join(\n",
    "#     dim_date_silver_df.select(\"date_sk\", \"full_date_str\", \"day_of_week\", \"day_name\"),\n",
    "#     fact_flight[\"flight_date_str\"] == dim_date_silver_df[\"full_date_str\"],\n",
    "#     \"inner\"\n",
    "# )\n",
    "\n",
    "\n",
    "# # Join with date dimension (preserve day_of_week for validation)\n",
    "# fact_flight = flights_clean.join(\n",
    "#     dim_date_silver_df.select(\"date_sk\", \"full_date\", \"day_of_week\", \"day_name\"),\n",
    "#     # fact_flight.flight_date == dim_date_silver_df.full_date,\n",
    "#     col(\"flight_date_str\") ==  col(\"full_date_str\"),\n",
    "#     \"inner\"\n",
    "# )\n",
    "# # .drop(\"flight_date\", \"full_date\", \"year\", \"month\", \"day\")\n",
    "# fact_flight.show(3)\n",
    "# fact_flight.select(\"flight_date\").distinct().show(5)\n",
    "# dim_date_silver_df.select(\"full_date\").distinct().show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_date_silver_df.printSchema()\n",
    "flights_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with date dimension (preserve day_of_week for validation)\n",
    "\n",
    "fact_flight = flights_clean.join(\n",
    "    dim_date_silver_df.select(\"date_sk\", \"full_date\", \"day_of_week\", \"day_name\"),\n",
    "    flights_clean.flight_date == dim_date_silver_df.full_date,\n",
    "    \"inner\"\n",
    ").drop(\"flight_date\", \"full_date\", \"year\", \"month\", \"day\")  # keep only surrogate key, not duplicate date cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbde125",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ef9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join airline dimension\n",
    "fact_flight = fact_flight.join(\n",
    "    dim_airline_silver_df.select(\"airline_sk\", \"iata_code\"), \n",
    "    flights_clean.airline == dim_airline_silver_df.iata_code, \n",
    "    \"inner\"\n",
    "    ).drop(\"airline\", \"iata_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0cd41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with origin airport dimension\n",
    "origin_airport_dim = dim_airport_silver_df.select(\n",
    "    col(\"airport_sk\").alias(\"origin_airport_sk\"),\n",
    "    col(\"iata_code\").alias(\"origin_iata\")\n",
    ")\n",
    "\n",
    "fact_flight = fact_flight.join(\n",
    "    origin_airport_dim,\n",
    "    fact_flight.origin_airport == col(\"origin_iata\"),\n",
    "    \"inner\"\n",
    ").drop(\"origin_airport\", \"origin_iata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83287739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with destination airport dimension\n",
    "dest_airport_dim = dim_airport_silver_df.select(\n",
    "    col(\"airport_sk\").alias(\"destination_airport_sk\"),\n",
    "    col(\"iata_code\").alias(\"dest_iata\")\n",
    ")\n",
    "\n",
    "fact_flight = fact_flight.join(\n",
    "    dest_airport_dim,\n",
    "    fact_flight.destination_airport == col(\"dest_iata\"),\n",
    "    \"inner\"\n",
    ").drop(\"destination_airport\", \"dest_iata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affe89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_flight.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9483d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Add surrogate key for the fact table\n",
    "fact_flight = fact_flight.withColumn(\"flight_sk\", monotonically_increasing_id())\n",
    "\n",
    "# Select and organize final columns\n",
    "fact_flight_final = fact_flight.select(\n",
    "    # Primary Key\n",
    "    col(\"flight_sk\"),\n",
    "    \n",
    "    # Foreign Keys (Surrogate Keys)\n",
    "    col(\"date_sk\"),\n",
    "    col(\"airline_sk\"),\n",
    "    col(\"origin_airport_sk\"),\n",
    "    col(\"destination_airport_sk\"),\n",
    "    \n",
    "    # Degenerate Dimensions\n",
    "    col(\"flight_number\"),\n",
    "    col(\"tail_number\"),\n",
    "    \n",
    "    # # Date attributes (from dimension)\n",
    "    # col(\"day_of_week\"),\n",
    "    # col(\"day_name\"),\n",
    "    \n",
    "    # Date attributes - Use qualified references from dimension table\n",
    "    col(\"unikargo_dev.02_silver.unikargo_dim_date_silver.day_of_week\"),\n",
    "    col(\"unikargo_dev.02_silver.unikargo_dim_date_silver.day_name\"),\n",
    "\n",
    "    # Measures (converting to appropriate data types)\n",
    "    col(\"scheduled_departure\").cast(\"int\"),\n",
    "    col(\"departure_time\").cast(\"int\"),\n",
    "    col(\"departure_delay\").cast(\"double\"),\n",
    "    col(\"taxi_out\").cast(\"double\"),\n",
    "    col(\"wheels_off\").cast(\"int\"),\n",
    "    col(\"scheduled_time\").cast(\"double\"),\n",
    "    col(\"elapsed_time\").cast(\"double\"),\n",
    "    col(\"air_time\").cast(\"double\"),\n",
    "    col(\"distance\").cast(\"double\"),\n",
    "    col(\"wheels_on\").cast(\"int\"),\n",
    "    col(\"taxi_in\").cast(\"double\"),\n",
    "    col(\"scheduled_arrival\").cast(\"int\"),\n",
    "    col(\"arrival_time\").cast(\"int\"),\n",
    "    col(\"arrival_delay\").cast(\"double\"),\n",
    "    col(\"diverted\").cast(\"int\"),\n",
    "    col(\"cancelled\").cast(\"int\")\n",
    "    # Note: Commented out columns that may not exist in all datasets\n",
    "    # col(\"cancellation_reason\"),\n",
    "    # col(\"air_system_delay\").cast(\"double\"),\n",
    "    # col(\"security_delay\").cast(\"double\"),\n",
    "    # col(\"airline_delay\").cast(\"double\"),\n",
    "    # col(\"late_aircraft_delay\").cast(\"double\"),\n",
    "    # col(\"weather_delay\").cast(\"double\")\n",
    ")\n",
    "\n",
    "print(f\"Fact table created with {fact_flight_final.count():,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50902dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample data\n",
    "print(\"Sample fact table data:\")\n",
    "fact_flight_final.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2E: SAVE FACT TABLE ===\n",
    "print(\"Saving fact table to silver layer...\")\n",
    "\n",
    "fact_flight_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"unikargo_dev.02_silver.unikargo_fact_flight_silver\")\n",
    "\n",
    "print(\"Flight fact table saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf03022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 2F: DATA QUALITY CHECKS ===\n",
    "print(\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "\n",
    "# Check day_of_week consistency (if original day_of_week exists in source)\n",
    "print(\"Checking day of week consistency...\")\n",
    "if \"day_of_week\" in flights_bronze_df.columns:\n",
    "    # Compare original vs calculated day_of_week\n",
    "    day_check = flights_clean.withColumn(\n",
    "        \"calculated_day_of_week\", \n",
    "        F.dayofweek(\"flight_date\")  # 1=Sunday, 2=Monday, etc.\n",
    "    ).withColumn(\n",
    "        \"original_day_of_week_adj\",\n",
    "        # Adjust original if it uses Monday=1 format vs Sunday=1\n",
    "        F.when(col(\"day_of_week\") == 7, 1)  # If original: Sunday=7, convert to 1\n",
    "         .when(col(\"day_of_week\") < 7, col(\"day_of_week\") + 1)  # Shift others\n",
    "         .otherwise(col(\"day_of_week\"))\n",
    "    ).filter(\n",
    "        col(\"calculated_day_of_week\") != col(\"original_day_of_week_adj\")\n",
    "    ).count()\n",
    "    \n",
    "    print(f\"Day of week mismatches: {day_check}\")\n",
    "\n",
    "# Check for orphaned records (should be 0 after inner joins)\n",
    "print(\"Checking data quality...\")\n",
    "\n",
    "# Verify all foreign keys exist\n",
    "date_check = fact_flight_final.join(dim_date_silver_df, [\"date_sk\"], \"left_anti\").count()\n",
    "airline_check = fact_flight_final.join(dim_airline_silver_df, [\"airline_sk\"], \"left_anti\").count()\n",
    "origin_check = fact_flight_final.join(\n",
    "    dim_airport_silver_df.select(col(\"airport_sk\").alias(\"origin_airport_sk\")), \n",
    "    [\"origin_airport_sk\"], \"left_anti\"\n",
    ").count()\n",
    "dest_check = fact_flight_final.join(\n",
    "    dim_airport_silver_df.select(col(\"airport_sk\").alias(\"destination_airport_sk\")), \n",
    "    [\"destination_airport_sk\"], \"left_anti\"\n",
    ").count()\n",
    "\n",
    "print(f\"Orphaned records check:\")\n",
    "print(f\"  - Date orphans: {date_check}\")\n",
    "print(f\"  - Airline orphans: {airline_check}\")\n",
    "print(f\"  - Origin airport orphans: {origin_check}\")\n",
    "print(f\"  - Destination airport orphans: {dest_check}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nFact table statistics:\")\n",
    "print(f\"  - Total flights: {fact_flight_final.count():,}\")\n",
    "print(f\"  - Date range: {fact_flight_final.count()} records\")\n",
    "print(f\"  - Unique airlines: {fact_flight_final.select('airline_sk').distinct().count()}\")\n",
    "print(f\"  - Unique origin airports: {fact_flight_final.select('origin_airport_sk').distinct().count()}\")\n",
    "print(f\"  - Unique destination airports: {fact_flight_final.select('destination_airport_sk').distinct().count()}\")\n",
    "\n",
    "# Check for null values in key columns\n",
    "null_checks = fact_flight_final.select([\n",
    "    F.sum(col(\"flight_sk\").isNull().cast(\"int\")).alias(\"flight_sk_nulls\"),\n",
    "    F.sum(col(\"date_sk\").isNull().cast(\"int\")).alias(\"date_sk_nulls\"),\n",
    "    F.sum(col(\"airline_sk\").isNull().cast(\"int\")).alias(\"airline_sk_nulls\"),\n",
    "    F.sum(col(\"origin_airport_sk\").isNull().cast(\"int\")).alias(\"origin_airport_sk_nulls\"),\n",
    "    F.sum(col(\"destination_airport_sk\").isNull().cast(\"int\")).alias(\"destination_airport_sk_nulls\")\n",
    "]).collect()[0]\n",
    "\n",
    "print(f\"\\nNull value checks:\")\n",
    "for field in null_checks.asDict():\n",
    "    print(f\"  - {field}: {null_checks[field]}\")\n",
    "\n",
    "print(\"\\n=== PIPELINE COMPLETED SUCCESSFULLY ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check date ranges in both tables\n",
    "# print(\"Date range in dim_date_silver_df:\")\n",
    "# dim_date_silver_df.select(F.min(\"full_date\"), F.max(\"full_date\")).show()\n",
    "\n",
    "# print(\"Date range in flights_clean:\")\n",
    "# flights_clean.select(F.min(\"flight_date\"), F.max(\"flight_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for nulls\n",
    "# print(\"Null count in dim_date_silver_df.full_date:\")\n",
    "# dim_date_silver_df.filter(F.col(\"full_date\").isNull()).count()\n",
    "\n",
    "# print(\"Null count in flights_clean.flight_date:\")\n",
    "# flights_clean.filter(F.col(\"flight_date\").isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find overlapping dates\n",
    "# overlapping_dates = flights_clean.select(\"flight_date\").distinct() \\\n",
    "#     .join(dim_date_silver_df.select(\"full_date\").distinct(), \n",
    "#           F.col(\"flight_date\") == F.col(\"full_date\"), \"inner\")\n",
    "# overlapping_dates.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dbc (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
